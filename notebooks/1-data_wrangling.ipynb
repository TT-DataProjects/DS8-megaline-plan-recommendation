{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rYiDeEH0q0f"
   },
   "source": [
    "# ¿Cuál es la mejor tarifa?\n",
    "\n",
    "Trabajas como analista para el operador de telecomunicaciones Megaline. La empresa ofrece a sus clientes dos tarifas de prepago, Surf y Ultimate. El departamento comercial quiere saber cuál de las tarifas genera más ingresos para poder ajustar el presupuesto de publicidad.\n",
    "\n",
    "Vas a realizar un análisis preliminar de las tarifas basado en una selección de clientes relativamente pequeña. Tendrás los datos de 500 clientes de Megaline: quiénes son los clientes, de dónde son, qué tarifa usan, así como la cantidad de llamadas que hicieron y los mensajes de texto que enviaron en 2018. Tu trabajo es analizar el comportamiento de los clientes y determinar qué tarifa de prepago genera más ingresos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNddPNRQ0q0w"
   },
   "source": [
    "**Propósito del proyecto: Determinar qué plan (surf o ultimate) es mejor para aconsejar a el departamento comercial acerca del presupuesto de publicidad.**\n",
    "\n",
    "Se estudiará la muestra de 500 usuarios para analizar el comportamiento del consumo y se buscaran respuesta a preguntas como:\n",
    "\n",
    "- ¿Qué plan usa más minutos, mensajes e Internet en promedio?\n",
    "- ¿Tienen estos planes tendencias diferentes o similares, los usuarios exceden los servicios ya incluidos en el plan?\n",
    "- ¿Qué plan genera más ingresos?\n",
    "\n",
    "**Interpretar los datos**: contamos con 5 tablas que nos brindan información importante acerca de:\n",
    "\n",
    "- `users` nos indica **características del usuario** como (id, nombre, edad y ciudad) lo cual nos permite hacer análisis demográficos. También nos indica datos de su (plan) y de fechas como (registro y cancelación)\n",
    "\n",
    "\n",
    "- `calls` permitirá analizar el **número de llamadas y minutos totales por cada usuario** y por fecha, dado que en `users` tenemos el ID de cada usuario y su plan podemos analizar este servicio.\n",
    "\n",
    "\n",
    "- `messages` permite conocer el **número total de mensajes enviados por cada usuario** y la fechas en que se realizó, nos ayudara a conocer el comportamiento por usuario y por ende por plan.\n",
    "\n",
    "\n",
    "- `internet` permite conocer la **cantidad de mb usados por cada usuario en cada sesión**, esta nos permitirá conocer el uso de internet.\n",
    "\n",
    "\n",
    "- `plans` contiene **la información de las tarifas de cada plan** (tanto base como adicionales) para cada uno de los servicios, será importante para determinar el ingreso por usuario y por plan teniendo en cuenta todo el uso de los servicios.\n",
    "\n",
    "Dadas las tablas que tenemos, es importante consolidar la información por usuario en una tabla que permita determinar el uso de servicios y el ingreso originado en cada uno de ellos. Posterior mente podemos analizar para cada plan cual es el ingreso promedio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQi4IPy70q0y"
   },
   "source": [
    "## Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MtYIuBxu0q0z",
    "ExecuteTime": {
     "end_time": "2024-08-04T14:33:51.513062Z",
     "start_time": "2024-08-04T14:33:16.921119Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import display\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_dq import dq_report\n",
    "from cryptography.fernet import Fernet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:33:51.558044Z",
     "start_time": "2024-08-04T14:33:51.516052Z"
    }
   },
   "outputs": [],
   "source": [
    "# append the path of the module to the sys.path\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from megaline import data_processing as mdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ysWWC5i0q00"
   },
   "source": [
    "## Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:33:51.590055Z",
     "start_time": "2024-08-04T14:33:51.560048Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the URLs for the data from the data_url.json file\n",
    "with open('../data/data_url.json', 'r') as f:\n",
    "    data_url = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users: Data Quality Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `churn_date` contine valores asuenes por los usuarios activos\n",
    "2. `city` contiene valores repetitivos que podemos remover como \"MSA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:33:52.136465Z",
     "start_time": "2024-08-04T14:33:51.592047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id first_name last_name   age                  city                   \\\n0   1000    Anamaria       Bauer  45   Atlanta-Sandy Springs-Roswell, GA MSA   \n1   1001      Mickey   Wilkerson  28         Seattle-Tacoma-Bellevue, WA MSA   \n\n    reg_date     plan    churn_date  \n0  2018-12-24  ultimate     NaN      \n1  2018-08-13      surf     NaN      ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: center;\">\n      <th></th>\n      <th>user_id</th>\n      <th>first_name</th>\n      <th>last_name</th>\n      <th>age</th>\n      <th>city</th>\n      <th>reg_date</th>\n      <th>plan</th>\n      <th>churn_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000</td>\n      <td>Anamaria</td>\n      <td>Bauer</td>\n      <td>45</td>\n      <td>Atlanta-Sandy Springs-Roswell, GA MSA</td>\n      <td>2018-12-24</td>\n      <td>ultimate</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1001</td>\n      <td>Mickey</td>\n      <td>Wilkerson</td>\n      <td>28</td>\n      <td>Seattle-Tacoma-Bellevue, WA MSA</td>\n      <td>2018-08-13</td>\n      <td>surf</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   user_id     2 non-null      int64  \n",
      " 1   first_name  2 non-null      object \n",
      " 2   last_name   2 non-null      object \n",
      " 3   age         2 non-null      int64  \n",
      " 4   city        2 non-null      object \n",
      " 5   reg_date    2 non-null      object \n",
      " 6   plan        2 non-null      object \n",
      " 7   churn_date  0 non-null      float64\n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 256.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "url = data_url[\"users\"]\n",
    "_ = pd.read_csv(url, nrows=2)\n",
    "display(_)\n",
    "_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:33:55.287090Z",
     "start_time": "2024-08-04T14:33:52.141436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Data Quality Report"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Missing Values"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:orange\">Missing values found:</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "churn_date    466\ndtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Duplicate Rows"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:green\">No duplicate rows found</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Constant Columns"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:green\">No constant columns found</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Categorical Columns with High Cardinality"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:orange\">Categorical columns with high cardinality found:</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "first_name    458\nlast_name     399\ncity           73\ndtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Numerical Columns with High Cardinality"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:green\">No numerical columns with high cardinality found</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Outliers"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:green\">No outliers found</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Correlated Columns"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:green\">No highly correlated columns found</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Data Quality Report"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a summary report. Change verbose to 1 to see more details on each DQ issue.\n",
      "    All variables classified into correct types.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x173bcb364d0>",
      "text/html": "<style type=\"text/css\">\n#T_219ee_row0_col0, #T_219ee_row1_col0 {\n  font-family: Segoe UI;\n}\n</style>\n<table id=\"T_219ee\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_219ee_level0_col0\" class=\"col_heading level0 col0\" >DQ Issue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_219ee_level0_row0\" class=\"row_heading level0 row0\" >The Good News</th>\n      <td id=\"T_219ee_row0_col0\" class=\"data row0 col0\" >There are no duplicate rows in this dataset, There are no duplicate columns in this datatset, There are no columns with infinite values in this dataset , There are no columns with mixed (more than one) dataypes in this dataset, There are no numeric columns with outliers in this dataset, There are no highly correlated columns in the dataset., There is no target given. Hence no target leakage columns detected in the dataset</td>\n    </tr>\n    <tr>\n      <th id=\"T_219ee_level0_row1\" class=\"row_heading level0 row1\" >The Bad News</th>\n      <td id=\"T_219ee_row1_col0\" class=\"data row1 col0\" >There are ID columns in the dataset. Remove them before modeling using Fix_DQ., These are zero-variance or low information columns in the dataset. Remove them before modeling., There are 1 date-time vars in the dataset. Make sure you transform them before modeling., There are 1 columns with high cardinality (>30 categories) in the dataset. Reduce them using encoding techniques or feature selection methods.</td>\n    </tr>\n  </tbody>\n</table>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "              Data Type     Missing Values%  Unique Values% Minimum Value  \\\nuser_id              int16        0.0              100          1000.0      \nfirst_name          object        0.0               91                      \nlast_name           object        0.0               79                      \nage                   int8        0.0               11            18.0      \ncity                object        0.0               14                      \nreg_date    datetime64[ns]        0.0               53                      \nplan                object        0.0                0                      \nchurn_date  datetime64[ns]       93.2                5                      \n\n           Maximum Value  \\\nuser_id        1499.0      \nfirst_name                 \nlast_name                  \nage              75.0      \ncity                       \nreg_date                   \nplan                       \nchurn_date                 \n\n                                                                                           DQ Issue                                                                                 \nuser_id                                                                                                                             Possible ID column: drop before modeling step.  \nfirst_name                                                                        458 rare categories: Too many to list. Group them into a single category or drop the categories.  \nlast_name                                                        Possible high cardinality column with 399 unique values: Use hash encoding or text embedding to reduce dimension.  \nage                                                                                                                                                                       No issue  \ncity                                                                               38 rare categories: Too many to list. Group them into a single category or drop the categories.  \nreg_date                                                                                                                 Possible date-time colum: transform before modeling step.  \nplan                                                                                                                                                                      No issue  \nchurn_date  Possible Zero-variance or low information colum: drop before modeling step., 466 missing values. Impute them with mean, median, mode, or a constant value such as 123.  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: center;\">\n      <th></th>\n      <th>Data Type</th>\n      <th>Missing Values%</th>\n      <th>Unique Values%</th>\n      <th>Minimum Value</th>\n      <th>Maximum Value</th>\n      <th>DQ Issue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>user_id</th>\n      <td>int16</td>\n      <td>0.0</td>\n      <td>100</td>\n      <td>1000.0</td>\n      <td>1499.0</td>\n      <td>Possible ID column: drop before modeling step.</td>\n    </tr>\n    <tr>\n      <th>first_name</th>\n      <td>object</td>\n      <td>0.0</td>\n      <td>91</td>\n      <td></td>\n      <td></td>\n      <td>458 rare categories: Too many to list. Group them into a single category or drop the categories.</td>\n    </tr>\n    <tr>\n      <th>last_name</th>\n      <td>object</td>\n      <td>0.0</td>\n      <td>79</td>\n      <td></td>\n      <td></td>\n      <td>Possible high cardinality column with 399 unique values: Use hash encoding or text embedding to reduce dimension.</td>\n    </tr>\n    <tr>\n      <th>age</th>\n      <td>int8</td>\n      <td>0.0</td>\n      <td>11</td>\n      <td>18.0</td>\n      <td>75.0</td>\n      <td>No issue</td>\n    </tr>\n    <tr>\n      <th>city</th>\n      <td>object</td>\n      <td>0.0</td>\n      <td>14</td>\n      <td></td>\n      <td></td>\n      <td>38 rare categories: Too many to list. Group them into a single category or drop the categories.</td>\n    </tr>\n    <tr>\n      <th>reg_date</th>\n      <td>datetime64[ns]</td>\n      <td>0.0</td>\n      <td>53</td>\n      <td></td>\n      <td></td>\n      <td>Possible date-time colum: transform before modeling step.</td>\n    </tr>\n    <tr>\n      <th>plan</th>\n      <td>object</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>No issue</td>\n    </tr>\n    <tr>\n      <th>churn_date</th>\n      <td>datetime64[ns]</td>\n      <td>93.2</td>\n      <td>5</td>\n      <td></td>\n      <td></td>\n      <td>Possible Zero-variance or low information colum: drop before modeling step., 466 missing values. Impute them with mean, median, mode, or a constant value such as 123.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users = mdp.downcast_dtypes(pd.read_csv(url,\n",
    "                                    #    index_col='user_id',\n",
    "                                       parse_dates=['reg_date', 'churn_date']))\n",
    "\n",
    "mdp.check_data_quality(df_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:33:55.303067Z",
     "start_time": "2024-08-04T14:33:55.290072Z"
    }
   },
   "outputs": [],
   "source": [
    "df_users = df_users.set_index(\"user_id\")\n",
    "\n",
    "# Separate the PII data, then standarize to capitalize the first letter of the first and last name\n",
    "pii_data = df_users[['first_name', 'last_name']]\n",
    "pii_data = pii_data.apply(lambda x: x.str.capitalize())\n",
    "\n",
    "# Drop PII column\n",
    "df_users.drop(['first_name', \"last_name\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:33:57.591801Z",
     "start_time": "2024-08-04T14:33:55.306072Z"
    }
   },
   "outputs": [],
   "source": [
    "key = Fernet.generate_key()\n",
    "cipher_suite = Fernet(key)\n",
    "\n",
    "def encrypt_name(name):\n",
    "    return cipher_suite.encrypt(name.encode()).decode()\n",
    "\n",
    "# Store the pii user data\n",
    "pii_data.map(encrypt_name).to_parquet(\"../data/clean/pii_data.parquet\", compression='brotli')\n",
    "\n",
    "# store the key\n",
    "with open(\"../data/clean/pii_data-key.txt\", \"w\") as f:\n",
    "    f.write(key.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:33:57.607790Z",
     "start_time": "2024-08-04T14:33:57.594785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed MSA from city names\n"
     ]
    }
   ],
   "source": [
    "if df_users[\"city\"].str.endswith(\" MSA\").mean() == 1:\n",
    "    df_users[\"city\"] = df_users[\"city\"].str[:-4]\n",
    "    print(\"Removed MSA from city names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:17.709157Z",
     "start_time": "2024-08-04T14:34:17.685164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         age                  city                   reg_date     plan    \\\nuser_id                                                                    \n1361     45                       birmingham-hoover 2018-04-14      surf   \n1073     30                chicago-naperville-elgin 2018-04-06      surf   \n1374     55             louisville/jefferson county 2018-02-14      surf   \n1155     19   miami-fort lauderdale-west palm beach 2018-02-21  ultimate   \n1104     20                chicago-naperville-elgin 2018-12-23  ultimate   \n\n        churn_date   state    \nuser_id                       \n1361       NaT            AL  \n1073       NaT      IL-IN-WI  \n1374       NaT         KY-IN  \n1155       NaT            FL  \n1104       NaT      IL-IN-WI  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: center;\">\n      <th></th>\n      <th>age</th>\n      <th>city</th>\n      <th>reg_date</th>\n      <th>plan</th>\n      <th>churn_date</th>\n      <th>state</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1361</th>\n      <td>45</td>\n      <td>birmingham-hoover</td>\n      <td>2018-04-14</td>\n      <td>surf</td>\n      <td>NaT</td>\n      <td>AL</td>\n    </tr>\n    <tr>\n      <th>1073</th>\n      <td>30</td>\n      <td>chicago-naperville-elgin</td>\n      <td>2018-04-06</td>\n      <td>surf</td>\n      <td>NaT</td>\n      <td>IL-IN-WI</td>\n    </tr>\n    <tr>\n      <th>1374</th>\n      <td>55</td>\n      <td>louisville/jefferson county</td>\n      <td>2018-02-14</td>\n      <td>surf</td>\n      <td>NaT</td>\n      <td>KY-IN</td>\n    </tr>\n    <tr>\n      <th>1155</th>\n      <td>19</td>\n      <td>miami-fort lauderdale-west palm beach</td>\n      <td>2018-02-21</td>\n      <td>ultimate</td>\n      <td>NaT</td>\n      <td>FL</td>\n    </tr>\n    <tr>\n      <th>1104</th>\n      <td>20</td>\n      <td>chicago-naperville-elgin</td>\n      <td>2018-12-23</td>\n      <td>ultimate</td>\n      <td>NaT</td>\n      <td>IL-IN-WI</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users[[\"city\", \"state\"]] = df_users.city.str.rsplit(\", \", n=1, expand=True)\n",
    "df_users[\"city\"] = df_users[\"city\"].str.lower()\n",
    "df_users[\"state\"] = df_users[\"state\"].str.upper()\n",
    "df_users.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    },
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:18.676919Z",
     "start_time": "2024-08-04T14:34:18.615899Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_users = df_users.assign(month=df_users[\"reg_date\"].dt.month, year=df_users[\"reg_date\"].dt.year)\n",
    "\n",
    "df_users[\"year_month\"] = df_users[\"reg_date\"].dt.to_period(\"M\")\n",
    "df_users = mdp.downcast_dtypes(df_users)\n",
    "\n",
    "df_users.to_parquet(\"../data/interim/df_users.parquet\", compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internet: Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:20.279217Z",
     "start_time": "2024-08-04T14:34:19.265897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id     user_id session_date  mb_used\n0   1000_13   1000    2018-12-29    89.86 \n1  1000_204   1000    2018-12-31     0.00 ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: center;\">\n      <th></th>\n      <th>id</th>\n      <th>user_id</th>\n      <th>session_date</th>\n      <th>mb_used</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000_13</td>\n      <td>1000</td>\n      <td>2018-12-29</td>\n      <td>89.86</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000_204</td>\n      <td>1000</td>\n      <td>2018-12-31</td>\n      <td>0.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            2 non-null      object \n",
      " 1   user_id       2 non-null      int64  \n",
      " 2   session_date  2 non-null      object \n",
      " 3   mb_used       2 non-null      float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 192.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "url = data_url[\"internet\"]\n",
    "_ = pd.read_csv(url, nrows=2)\n",
    "display(_)\n",
    "_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:22.120453Z",
     "start_time": "2024-08-04T14:34:20.283215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Data Quality Report"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Missing Values"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:green\">No missing values found</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Duplicate Rows"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:orange\">1731 duplicate rows found</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Constant Columns"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:green\">No constant columns found</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Categorical Columns with High Cardinality"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:green\">No categorical columns with high cardinality found</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Numerical Columns with High Cardinality"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:orange\">Numerical columns with high cardinality found:</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "user_id      489\nmb_used    57624\ndtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Outliers"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:orange\">Outliers found:</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'mb_used': np.int64(371)}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Correlated Columns"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:green\">No highly correlated columns found</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Data Quality Report"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a summary report. Change verbose to 1 to see more details on each DQ issue.\n",
      "There are 1731 duplicate rows in your dataset\n",
      "    Alert: Dropping duplicate rows can sometimes cause your column data types to change to object!\n",
      "    All variables classified into correct types.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x173c004a410>",
      "text/html": "<style type=\"text/css\">\n#T_8f77c_row0_col0, #T_8f77c_row1_col0 {\n  font-family: Segoe UI;\n}\n</style>\n<table id=\"T_8f77c\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_8f77c_level0_col0\" class=\"col_heading level0 col0\" >DQ Issue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_8f77c_level0_row0\" class=\"row_heading level0 row0\" >The Good News</th>\n      <td id=\"T_8f77c_row0_col0\" class=\"data row0 col0\" >There are no duplicate columns in this datatset, There are no ID columns in the dataset., There are no zero-variance or low information columns in the dataset., There are no columns with missing values in the dataset, There are no categorical columns with rare categories (< 1 percent) in this dataset, There are no columns with infinite values in this dataset , There are no columns with mixed (more than one) dataypes in this dataset, There are no high cardinality columns in this dataset, There are no highly correlated columns in the dataset., There is no target given. Hence no target leakage columns detected in the dataset</td>\n    </tr>\n    <tr>\n      <th id=\"T_8f77c_level0_row1\" class=\"row_heading level0 row1\" >The Bad News</th>\n      <td id=\"T_8f77c_row1_col0\" class=\"data row1 col0\" >There are 1731 duplicate rows in the dataset. De-Dup these rows using Fix_DQ., There are 1 date-time vars in the dataset. Make sure you transform them before modeling., There are 2 numerical columns, some with outliers. Remove them or use robust statistics.</td>\n    </tr>\n  </tbody>\n</table>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                Data Type     Missing Values% Unique Values% Minimum Value  \\\nuser_id                int64        0.0              0           1000.0      \nsession_date  datetime64[ns]        0.0              0                       \nmb_used              float64        0.0             NA              0.0      \n\n             Maximum Value  \\\nuser_id           1499.0     \nsession_date                 \nmb_used          1693.47     \n\n                                                                     DQ Issue                                                          \nuser_id                                                                                                                      No issue  \nsession_date                                                                Possible date-time colum: transform before modeling step.  \nmb_used       Column has 455 outliers greater than upper bound (1174.70) or lower than lower bound(-468.35). Cap them or remove them.  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: center;\">\n      <th></th>\n      <th>Data Type</th>\n      <th>Missing Values%</th>\n      <th>Unique Values%</th>\n      <th>Minimum Value</th>\n      <th>Maximum Value</th>\n      <th>DQ Issue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>user_id</th>\n      <td>int64</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1000.0</td>\n      <td>1499.0</td>\n      <td>No issue</td>\n    </tr>\n    <tr>\n      <th>session_date</th>\n      <td>datetime64[ns]</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>Possible date-time colum: transform before modeling step.</td>\n    </tr>\n    <tr>\n      <th>mb_used</th>\n      <td>float64</td>\n      <td>0.0</td>\n      <td>NA</td>\n      <td>0.0</td>\n      <td>1693.47</td>\n      <td>Column has 455 outliers greater than upper bound (1174.70) or lower than lower bound(-468.35). Cap them or remove them.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_internet = pd.read_csv(url,index_col='id', parse_dates=['session_date'])\n",
    "\n",
    "mdp.check_data_quality(df_internet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:22.761402Z",
     "start_time": "2024-08-04T14:34:22.122457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use assign to include a year and month columns\n",
    "df_internet = df_internet.assign(year_month=df_internet['session_date'].dt.to_period('M'))\n",
    "df_internet['gb_used'] = df_internet['mb_used'].div(1024)\n",
    "df_internet = mdp.downcast_dtypes(df_internet.drop('mb_used', axis=1))\n",
    "\n",
    "df_internet.to_parquet(\"../data/clean/internet.parquet\", compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMS: Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:23.818929Z",
     "start_time": "2024-08-04T14:34:22.766405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id     user_id message_date\n0  1000_125   1000    2018-12-27 \n1  1000_160   1000    2018-12-31 ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: center;\">\n      <th></th>\n      <th>id</th>\n      <th>user_id</th>\n      <th>message_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000_125</td>\n      <td>1000</td>\n      <td>2018-12-27</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000_160</td>\n      <td>1000</td>\n      <td>2018-12-31</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            2 non-null      object\n",
      " 1   user_id       2 non-null      int64 \n",
      " 2   message_date  2 non-null      object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 176.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "url = data_url[\"sms\"]\n",
    "_ = pd.read_csv(url, nrows=2)\n",
    "display(_)\n",
    "_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:25.031912Z",
     "start_time": "2024-08-04T14:34:23.821932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Data Quality Report"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Missing Values"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:green\">No missing values found</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Duplicate Rows"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:orange\">42808 duplicate rows found</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Constant Columns"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:green\">No constant columns found</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Categorical Columns with High Cardinality"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:green\">No categorical columns with high cardinality found</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Numerical Columns with High Cardinality"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:orange\">Numerical columns with high cardinality found:</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "user_id    402\ndtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Outliers"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:green\">No outliers found</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Correlated Columns"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:green\">No highly correlated columns found</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Data Quality Report"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a summary report. Change verbose to 1 to see more details on each DQ issue.\n",
      "There are 42808 duplicate rows in your dataset\n",
      "    Alert: Dropping duplicate rows can sometimes cause your column data types to change to object!\n",
      "    All variables classified into correct types.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x173c2c68880>",
      "text/html": "<style type=\"text/css\">\n#T_86b3c_row0_col0, #T_86b3c_row1_col0 {\n  font-family: Segoe UI;\n}\n</style>\n<table id=\"T_86b3c\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_86b3c_level0_col0\" class=\"col_heading level0 col0\" >DQ Issue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_86b3c_level0_row0\" class=\"row_heading level0 row0\" >The Good News</th>\n      <td id=\"T_86b3c_row0_col0\" class=\"data row0 col0\" >There are no duplicate columns in this datatset, There are no ID columns in the dataset., There are no zero-variance or low information columns in the dataset., There are no columns with missing values in the dataset, There are no categorical columns with rare categories (< 1 percent) in this dataset, There are no columns with infinite values in this dataset , There are no columns with mixed (more than one) dataypes in this dataset, There are no numeric columns with outliers in this dataset, There are no high cardinality columns in this dataset, There are no highly correlated columns in the dataset., There is no target given. Hence no target leakage columns detected in the dataset</td>\n    </tr>\n    <tr>\n      <th id=\"T_86b3c_level0_row1\" class=\"row_heading level0 row1\" >The Bad News</th>\n      <td id=\"T_86b3c_row1_col0\" class=\"data row1 col0\" >There are 42808 duplicate rows in the dataset. De-Dup these rows using Fix_DQ., There are 1 date-time vars in the dataset. Make sure you transform them before modeling.</td>\n    </tr>\n  </tbody>\n</table>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                Data Type     Missing Values%  Unique Values% Minimum Value  \\\nuser_id                int64        0.0               1           1000.0      \nmessage_date  datetime64[ns]        0.0               1                       \n\n             Maximum Value  \\\nuser_id          1497.0      \nmessage_date                 \n\n                                      DQ Issue                           \nuser_id                                                        No issue  \nmessage_date  Possible date-time colum: transform before modeling step.  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: center;\">\n      <th></th>\n      <th>Data Type</th>\n      <th>Missing Values%</th>\n      <th>Unique Values%</th>\n      <th>Minimum Value</th>\n      <th>Maximum Value</th>\n      <th>DQ Issue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>user_id</th>\n      <td>int64</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1000.0</td>\n      <td>1497.0</td>\n      <td>No issue</td>\n    </tr>\n    <tr>\n      <th>message_date</th>\n      <td>datetime64[ns]</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td>Possible date-time colum: transform before modeling step.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sms = pd.read_csv(url,index_col='id', parse_dates=['message_date'])\n",
    "\n",
    "mdp.check_data_quality(df_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:25.543919Z",
     "start_time": "2024-08-04T14:34:25.035915Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use assign to include a year and month columns\n",
    "df_sms = df_sms.assign(year_month=df_sms['message_date'].dt.to_period(\"M\"))\n",
    "df_sms = mdp.downcast_dtypes(df_sms)\n",
    "\n",
    "df_sms.to_parquet(\"../data/clean/sms.parquet\", compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calls: Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:26.693374Z",
     "start_time": "2024-08-04T14:34:25.546919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      id     user_id  call_date   duration\n0   1000_93   1000    2018-12-27     8.52 \n1  1000_145   1000    2018-12-27    13.66 ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: center;\">\n      <th></th>\n      <th>id</th>\n      <th>user_id</th>\n      <th>call_date</th>\n      <th>duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000_93</td>\n      <td>1000</td>\n      <td>2018-12-27</td>\n      <td>8.52</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000_145</td>\n      <td>1000</td>\n      <td>2018-12-27</td>\n      <td>13.66</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   id         2 non-null      object \n",
      " 1   user_id    2 non-null      int64  \n",
      " 2   call_date  2 non-null      object \n",
      " 3   duration   2 non-null      float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 192.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "url = data_url[\"calls\"]\n",
    "_ = pd.read_csv(url, nrows=2)\n",
    "display(_)\n",
    "_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:29.136343Z",
     "start_time": "2024-08-04T14:34:26.696364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "### Data Quality Report"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Missing Values"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:green\">No missing values found</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Duplicate Rows"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:orange\">5882 duplicate rows found</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Constant Columns"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:green\">No constant columns found</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Categorical Columns with High Cardinality"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:green\">No categorical columns with high cardinality found</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Numerical Columns with High Cardinality"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:orange\">Numerical columns with high cardinality found:</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "user_id      481\nduration    2802\ndtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Outliers"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:orange\">Outliers found:</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'duration': np.int64(635)}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Correlated Columns"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "<span style=\"color:green\">No highly correlated columns found</span>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "#### Data Quality Report"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a summary report. Change verbose to 1 to see more details on each DQ issue.\n",
      "There are 5882 duplicate rows in your dataset\n",
      "    Alert: Dropping duplicate rows can sometimes cause your column data types to change to object!\n",
      "    All variables classified into correct types.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x173bca40d00>",
      "text/html": "<style type=\"text/css\">\n#T_a3516_row0_col0, #T_a3516_row1_col0 {\n  font-family: Segoe UI;\n}\n</style>\n<table id=\"T_a3516\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_a3516_level0_col0\" class=\"col_heading level0 col0\" >DQ Issue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_a3516_level0_row0\" class=\"row_heading level0 row0\" >The Good News</th>\n      <td id=\"T_a3516_row0_col0\" class=\"data row0 col0\" >There are no duplicate columns in this datatset, There are no ID columns in the dataset., There are no zero-variance or low information columns in the dataset., There are no columns with missing values in the dataset, There are no categorical columns with rare categories (< 1 percent) in this dataset, There are no columns with infinite values in this dataset , There are no columns with mixed (more than one) dataypes in this dataset, There are no high cardinality columns in this dataset, There are no highly correlated columns in the dataset., There is no target given. Hence no target leakage columns detected in the dataset</td>\n    </tr>\n    <tr>\n      <th id=\"T_a3516_level0_row1\" class=\"row_heading level0 row1\" >The Bad News</th>\n      <td id=\"T_a3516_row1_col0\" class=\"data row1 col0\" >There are 5882 duplicate rows in the dataset. De-Dup these rows using Fix_DQ., There are 1 date-time vars in the dataset. Make sure you transform them before modeling., There are 2 numerical columns, some with outliers. Remove them or use robust statistics.</td>\n    </tr>\n  </tbody>\n</table>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "             Data Type     Missing Values% Unique Values% Minimum Value  \\\nuser_id             int64        0.0              0           1000.0      \ncall_date  datetime64[ns]        0.0              0                       \nduration          float64        0.0             NA              0.0      \n\n          Maximum Value  \\\nuser_id       1499.0      \ncall_date                 \nduration        37.6      \n\n                                                                 DQ Issue                                                        \nuser_id                                                                                                                No issue  \ncall_date                                                             Possible date-time colum: transform before modeling step.  \nduration   Column has 604 outliers greater than upper bound (24.38) or lower than lower bound(-11.49). Cap them or remove them.  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: center;\">\n      <th></th>\n      <th>Data Type</th>\n      <th>Missing Values%</th>\n      <th>Unique Values%</th>\n      <th>Minimum Value</th>\n      <th>Maximum Value</th>\n      <th>DQ Issue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>user_id</th>\n      <td>int64</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1000.0</td>\n      <td>1499.0</td>\n      <td>No issue</td>\n    </tr>\n    <tr>\n      <th>call_date</th>\n      <td>datetime64[ns]</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>Possible date-time colum: transform before modeling step.</td>\n    </tr>\n    <tr>\n      <th>duration</th>\n      <td>float64</td>\n      <td>0.0</td>\n      <td>NA</td>\n      <td>0.0</td>\n      <td>37.6</td>\n      <td>Column has 604 outliers greater than upper bound (24.38) or lower than lower bound(-11.49). Cap them or remove them.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_calls = pd.read_csv(url,index_col='id', parse_dates=['call_date'])\n",
    "\n",
    "mdp.check_data_quality(df_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. No hay datos ausentes en la tabla.\n",
    "2. `duration` contiene los minutos en decimales, Megaline cobra el minuto completo (usar np.ceil) para resolver este problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:29.167200Z",
     "start_time": "2024-08-04T14:34:29.141334Z"
    }
   },
   "outputs": [],
   "source": [
    "df_calls['minutes'] = np.ceil(df_calls['duration'])  # redondeo hacia arriba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:29.850646Z",
     "start_time": "2024-08-04T14:34:29.170194Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use assign to include a year and month columns\n",
    "df_calls = df_calls.assign(year_month=df_calls['call_date'].dt.to_period(\"M\"))\n",
    "df_calls = mdp.downcast_dtypes(df_calls.drop('duration', axis=1))\n",
    "\n",
    "df_calls.to_parquet(\"../data/clean/calls.parquet\", compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planes: Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:30.286291Z",
     "start_time": "2024-08-04T14:34:29.854646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   messages_included  mb_per_month_included  minutes_included  \\\n0          50                 15360                 500         \n1        1000                 30720                3000         \n\n   usd_monthly_pay  usd_per_gb  usd_per_message  usd_per_minute plan_name  \n0        20             10           0.03             0.03           surf  \n1        70              7           0.01             0.01       ultimate  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: center;\">\n      <th></th>\n      <th>messages_included</th>\n      <th>mb_per_month_included</th>\n      <th>minutes_included</th>\n      <th>usd_monthly_pay</th>\n      <th>usd_per_gb</th>\n      <th>usd_per_message</th>\n      <th>usd_per_minute</th>\n      <th>plan_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50</td>\n      <td>15360</td>\n      <td>500</td>\n      <td>20</td>\n      <td>10</td>\n      <td>0.03</td>\n      <td>0.03</td>\n      <td>surf</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000</td>\n      <td>30720</td>\n      <td>3000</td>\n      <td>70</td>\n      <td>7</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>ultimate</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_plans = pd.read_csv(data_url[\"plans\"])\n",
    "df_plans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEc_3_hs0q02"
   },
   "source": [
    "`mb_per_month_included` debe convertirse a GB usando la formula (1gb = 1024 Mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Y7SVmjGn0q03",
    "outputId": "302c158f-90bc-49f9-9e4f-430e9b73a850",
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:30.317255Z",
     "start_time": "2024-08-04T14:34:30.286291Z"
    }
   },
   "outputs": [],
   "source": [
    "#Megaline cobra por gb no mb, creo una col con los valores en Gb (1 GB = 1024 Mb)\n",
    "\n",
    "df_plans[\"gb_per_month_included\"] = df_plans[\"mb_per_month_included\"]/1024\n",
    "del df_plans[\"mb_per_month_included\"]\n",
    "df_plans = mdp.downcast_dtypes(df_plans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:30.363261Z",
     "start_time": "2024-08-04T14:34:30.319256Z"
    }
   },
   "outputs": [],
   "source": [
    "df_plans = df_plans.rename(\n",
    "    columns={\n",
    "        # \"plan_name\": \"plan\",\n",
    "        \"usd_monthly_pay\": \"monthly_plan_fee\",\n",
    "        \n",
    "        \"usd_per_gb\": \"price_gb\",\n",
    "        \"usd_per_message\": \"price_sms\",\n",
    "        \"usd_per_minute\": \"price_minute\",\n",
    "\n",
    "        \"gb_per_month_included\": \"included_gb\",\n",
    "        \"messages_included\": \"included_sms\",\n",
    "        \"minutes_included\": \"included_minutes\",\n",
    "\n",
    "    }\n",
    ")\n",
    "df_plans.to_parquet(\"../data/clean/plans.parquet\", compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMR1tP5d0q1F"
   },
   "source": [
    "## Agregar datos por usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Fue2RC9T2bas",
    "outputId": "dcdb7296-af40-4def-ca39-68def0c20af8",
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:30.409251Z",
     "start_time": "2024-08-04T14:34:30.366269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                    calls_count  minutes_sum\nuser_id year_month                          \n1000    2018-12         16          124.0   \n1001    2018-08         27          182.0   \n        2018-09         49          315.0   \n        2018-10         65          393.0   \n        2018-11         64          426.0   \n...                         ...          ...\n1498    2018-12         39          339.0   \n1499    2018-09         41          346.0   \n        2018-10         53          385.0   \n        2018-11         45          308.0   \n        2018-12         65          496.0   \n\n[2258 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: center;\">\n      <th></th>\n      <th></th>\n      <th>calls_count</th>\n      <th>minutes_sum</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th>year_month</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1000</th>\n      <th>2018-12</th>\n      <td>16</td>\n      <td>124.0</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">1001</th>\n      <th>2018-08</th>\n      <td>27</td>\n      <td>182.0</td>\n    </tr>\n    <tr>\n      <th>2018-09</th>\n      <td>49</td>\n      <td>315.0</td>\n    </tr>\n    <tr>\n      <th>2018-10</th>\n      <td>65</td>\n      <td>393.0</td>\n    </tr>\n    <tr>\n      <th>2018-11</th>\n      <td>64</td>\n      <td>426.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1498</th>\n      <th>2018-12</th>\n      <td>39</td>\n      <td>339.0</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">1499</th>\n      <th>2018-09</th>\n      <td>41</td>\n      <td>346.0</td>\n    </tr>\n    <tr>\n      <th>2018-10</th>\n      <td>53</td>\n      <td>385.0</td>\n    </tr>\n    <tr>\n      <th>2018-11</th>\n      <td>45</td>\n      <td>308.0</td>\n    </tr>\n    <tr>\n      <th>2018-12</th>\n      <td>65</td>\n      <td>496.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2258 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcula el número de llamadas hechas por cada usuario al mes y los minutos totales\n",
    "user_calls = df_calls.groupby([\"user_id\", \"year_month\"]).agg(\n",
    "    calls_count=pd.NamedAgg(column='minutes', aggfunc='size'),\n",
    "    minutes_sum=pd.NamedAgg(column='minutes', aggfunc='sum')\n",
    ")\n",
    "\n",
    "user_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "CcQvNHn60q1G",
    "outputId": "590f8667-6b1f-45bb-bd05-6d9805ce26c9",
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:30.440253Z",
     "start_time": "2024-08-04T14:34:30.411262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                    sms_count\nuser_id year_month           \n1000    2018-12        11    \n1001    2018-08        30    \n        2018-09        44    \n        2018-10        53    \n        2018-11        36    \n...                       ...\n1496    2018-09        21    \n        2018-10        18    \n        2018-11        13    \n        2018-12        11    \n1497    2018-12        50    \n\n[1806 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: center;\">\n      <th></th>\n      <th></th>\n      <th>sms_count</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th>year_month</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1000</th>\n      <th>2018-12</th>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">1001</th>\n      <th>2018-08</th>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>2018-09</th>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>2018-10</th>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>2018-11</th>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">1496</th>\n      <th>2018-09</th>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>2018-10</th>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>2018-11</th>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>2018-12</th>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1497</th>\n      <th>2018-12</th>\n      <td>50</td>\n    </tr>\n  </tbody>\n</table>\n<p>1806 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcula el número de mensajes enviados por cada usuario al mes. (as a DataFrame)\n",
    "user_sms = df_sms.groupby([\"user_id\", \"year_month\"]).size().to_frame(name=\"sms_count\")\n",
    "user_sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "H1AqN2eG0q1H",
    "outputId": "7f339fdf-1ba9-4974-8abc-04e0c9b9bbfe",
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:30.470254Z",
     "start_time": "2024-08-04T14:34:30.442257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                    gb_used\nuser_id year_month         \n1000    2018-12       2.0  \n1001    2018-08       7.0  \n        2018-09      14.0  \n        2018-10      22.0  \n        2018-11      19.0  \n...                     ...\n1498    2018-12      23.0  \n1499    2018-09      13.0  \n        2018-10      20.0  \n        2018-11      17.0  \n        2018-12      22.0  \n\n[2277 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: center;\">\n      <th></th>\n      <th></th>\n      <th>gb_used</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th>year_month</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1000</th>\n      <th>2018-12</th>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">1001</th>\n      <th>2018-08</th>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>2018-09</th>\n      <td>14.0</td>\n    </tr>\n    <tr>\n      <th>2018-10</th>\n      <td>22.0</td>\n    </tr>\n    <tr>\n      <th>2018-11</th>\n      <td>19.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1498</th>\n      <th>2018-12</th>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">1499</th>\n      <th>2018-09</th>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>2018-10</th>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>2018-11</th>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>2018-12</th>\n      <td>22.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2277 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcula el volumen del tráfico de Internet usado por cada usuario al mes. (as a DataFrame)\n",
    "user_internet = df_internet.groupby([\"user_id\", \"year_month\"]).agg(\n",
    "    gb_used=pd.NamedAgg(column='gb_used', aggfunc='sum')\n",
    ")\n",
    "\n",
    "\n",
    "#ejemplo en instrucciones (web/mes 1205 mb -> 2gb)\n",
    "user_internet['gb_used'] = user_internet['gb_used'].apply(np.ceil)  #round up por mes\n",
    "user_internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:30.485252Z",
     "start_time": "2024-08-04T14:34:30.473265Z"
    }
   },
   "outputs": [],
   "source": [
    "# add year_month as second index for df_users\n",
    "df_users = df_users.set_index('year_month', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:30.517264Z",
     "start_time": "2024-08-04T14:34:30.487253Z"
    }
   },
   "outputs": [],
   "source": [
    "user_monthly_data = (\n",
    "    df_users[['plan', 'churn_date']].join(user_calls, how='outer')\n",
    "            .join(user_sms, how='outer')\n",
    "            .join(user_internet, how='outer')\n",
    "    ).rename(columns=\n",
    "         {\n",
    "            \"plan\":\"plan_name\",\n",
    "            \"minutes_sum\": \"total_minutes\",\n",
    "            \"sms_count\": \"total_sms\",\n",
    "            \"gb_used\":\"total_gb\"\n",
    "          }\n",
    "    ).sort_index(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:30.847400Z",
     "start_time": "2024-08-04T14:34:30.520256Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_19604\\963937332.py:2: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "  user_monthly_data['plan_name'] = user_monthly_data.groupby(level=0)['plan_name'].fillna(method='ffill')\n",
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_19604\\963937332.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  user_monthly_data['plan_name'] = user_monthly_data.groupby(level=0)['plan_name'].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "user_monthly_data[[\"calls_count\", \"total_minutes\", \"total_sms\", \"total_gb\"]] = user_monthly_data[[\"calls_count\", \"total_minutes\", \"total_sms\", \"total_gb\"]].fillna(0)\n",
    "user_monthly_data['plan_name'] = user_monthly_data.groupby(level=0)['plan_name'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:30.973422Z",
     "start_time": "2024-08-04T14:34:30.848924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a summary report. Change verbose to 1 to see more details on each DQ issue.\n",
      "There are 235 duplicate rows in your dataset\n",
      "    Alert: Dropping duplicate rows can sometimes cause your column data types to change to object!\n",
      "    All variables classified into correct types.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guill\\AppData\\Local\\Temp\\ipykernel_19604\\584651055.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  dq_report(user_monthly_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x173c2c6b400>",
      "text/html": "<style type=\"text/css\">\n#T_048e5_row0_col0, #T_048e5_row1_col0 {\n  font-family: Segoe UI;\n}\n</style>\n<table id=\"T_048e5\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_048e5_level0_col0\" class=\"col_heading level0 col0\" >DQ Issue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_048e5_level0_row0\" class=\"row_heading level0 row0\" >The Good News</th>\n      <td id=\"T_048e5_row0_col0\" class=\"data row0 col0\" >There are no duplicate columns in this datatset, There are no ID columns in the dataset., There are no date-time vars in this dataset, There are no categorical columns with rare categories (< 1 percent) in this dataset, There are no columns with infinite values in this dataset , There are no columns with mixed (more than one) dataypes in this dataset, There are no high cardinality columns in this dataset, There is no target given. Hence no target leakage columns detected in the dataset</td>\n    </tr>\n    <tr>\n      <th id=\"T_048e5_level0_row1\" class=\"row_heading level0 row1\" >The Bad News</th>\n      <td id=\"T_048e5_row1_col0\" class=\"data row1 col0\" >There are 235 duplicate rows in the dataset. De-Dup these rows using Fix_DQ., These are zero-variance or low information columns in the dataset. Remove them before modeling., There are 4 numerical columns, some with outliers. Remove them or use robust statistics., There are 1 columns with >= 0.8 correlation in the dataset. Drop one of them or use dimensionality reduction techniques.</td>\n    </tr>\n  </tbody>\n</table>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                 Data Type     Missing Values% Unique Values% Minimum Value  \\\nplan_name              object      0.000000           0                       \nchurn_date     datetime64[ns]     98.528775           1                       \ncalls_count           float64      0.000000          NA             0.0       \ntotal_minutes         float32      0.000000          NA             0.0       \ntotal_sms             float64      0.000000          NA             0.0       \ntotal_gb              float32      0.000000          NA             0.0       \n\n              Maximum Value  \\\nplan_name                     \nchurn_date                    \ncalls_count        205.0      \ntotal_minutes     1510.0      \ntotal_sms          266.0      \ntotal_gb            70.0      \n\n                                                                                                                DQ Issue                                                                                                   \nplan_name                                                                                                                                                                                                        No issue  \nchurn_date                                        Possible Zero-variance or low information colum: drop before modeling step., 2277 missing values. Impute them with mean, median, mode, or a constant value such as 123.  \ncalls_count                                                                                          Column has 43 outliers greater than upper bound (142.00) or lower than lower bound(-26.00). Cap them or remove them.  \ntotal_minutes  Column has 42 outliers greater than upper bound (1035.50) or lower than lower bound(-204.50). Cap them or remove them., Column has a high correlation with ['calls_count']. Consider dropping one of them.  \ntotal_sms                                                                                            Column has 58 outliers greater than upper bound (123.00) or lower than lower bound(-69.00). Cap them or remove them.  \ntotal_gb                                                                                               Column has 59 outliers greater than upper bound (34.50) or lower than lower bound(-1.50). Cap them or remove them.  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: center;\">\n      <th></th>\n      <th>Data Type</th>\n      <th>Missing Values%</th>\n      <th>Unique Values%</th>\n      <th>Minimum Value</th>\n      <th>Maximum Value</th>\n      <th>DQ Issue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>plan_name</th>\n      <td>object</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td></td>\n      <td></td>\n      <td>No issue</td>\n    </tr>\n    <tr>\n      <th>churn_date</th>\n      <td>datetime64[ns]</td>\n      <td>98.528775</td>\n      <td>1</td>\n      <td></td>\n      <td></td>\n      <td>Possible Zero-variance or low information colum: drop before modeling step., 2277 missing values. Impute them with mean, median, mode, or a constant value such as 123.</td>\n    </tr>\n    <tr>\n      <th>calls_count</th>\n      <td>float64</td>\n      <td>0.000000</td>\n      <td>NA</td>\n      <td>0.0</td>\n      <td>205.0</td>\n      <td>Column has 43 outliers greater than upper bound (142.00) or lower than lower bound(-26.00). Cap them or remove them.</td>\n    </tr>\n    <tr>\n      <th>total_minutes</th>\n      <td>float32</td>\n      <td>0.000000</td>\n      <td>NA</td>\n      <td>0.0</td>\n      <td>1510.0</td>\n      <td>Column has 42 outliers greater than upper bound (1035.50) or lower than lower bound(-204.50). Cap them or remove them., Column has a high correlation with ['calls_count']. Consider dropping one of them.</td>\n    </tr>\n    <tr>\n      <th>total_sms</th>\n      <td>float64</td>\n      <td>0.000000</td>\n      <td>NA</td>\n      <td>0.0</td>\n      <td>266.0</td>\n      <td>Column has 58 outliers greater than upper bound (123.00) or lower than lower bound(-69.00). Cap them or remove them.</td>\n    </tr>\n    <tr>\n      <th>total_gb</th>\n      <td>float32</td>\n      <td>0.000000</td>\n      <td>NA</td>\n      <td>0.0</td>\n      <td>70.0</td>\n      <td>Column has 59 outliers greater than upper bound (34.50) or lower than lower bound(-1.50). Cap them or remove them.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dq_report(user_monthly_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:31.068423Z",
     "start_time": "2024-08-04T14:34:30.975429Z"
    }
   },
   "outputs": [],
   "source": [
    "mdp.downcast_dtypes(user_monthly_data).to_parquet(\"../data/clean/user_monthly_data.parquet\", compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:31.193416Z",
     "start_time": "2024-08-04T14:34:31.071426Z"
    }
   },
   "outputs": [],
   "source": [
    "# Añade la información de la tarifa\n",
    "df = (user_monthly_data\n",
    "        .reset_index()\n",
    "        .merge(df_plans, on='plan_name', how='left')\n",
    "        .set_index([\"user_id\", \"year_month\"])\n",
    ")\n",
    "df = df.assign(\n",
    "    excess_usage=(\n",
    "    (df['total_gb'] - df[\"included_gb\"]).clip(0) * df['price_gb'] +\n",
    "    (df['total_minutes'] - df[\"included_minutes\"]).clip(0) * df['price_minute'] +\n",
    "    (df['total_sms'] - df[\"included_sms\"]).clip(0) * df['price_sms']\n",
    "    ),\n",
    "    total_payment=lambda x: x['monthly_plan_fee'] + x['excess_usage']\n",
    ").drop(\"churn_date\", axis=1)\n",
    "df.to_parquet(\"../data/clean/usage_data.parquet\", compression='brotli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T14:34:31.287415Z",
     "start_time": "2024-08-04T14:34:31.196420Z"
    }
   },
   "outputs": [],
   "source": [
    "#join user data: usage_data\n",
    "df = df[sorted(df.columns)]\n",
    "(df.join(df_users)[[\"plan_name\", \"state\", \"monthly_plan_fee\",\n",
    "                    'calls_count', 'total_minutes', 'total_sms', 'total_gb',\n",
    "                    \"excess_usage\", \"total_payment\"]]\n",
    " .to_parquet(\"../data/clean/usage_data.parquet\", compression='brotli'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 828,
    "start_time": "2021-11-16T09:21:11.304Z"
   },
   {
    "duration": 893,
    "start_time": "2021-11-16T09:21:17.728Z"
   },
   {
    "duration": 1150,
    "start_time": "2021-11-16T09:21:29.568Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T09:24:14.495Z"
   },
   {
    "duration": 120,
    "start_time": "2021-11-16T09:24:46.630Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T09:28:27.882Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T09:29:54.281Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T09:30:45.936Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T09:31:06.300Z"
   },
   {
    "duration": 113,
    "start_time": "2021-11-16T09:31:37.208Z"
   },
   {
    "duration": 143,
    "start_time": "2021-11-16T09:31:48.656Z"
   },
   {
    "duration": 98,
    "start_time": "2021-11-16T09:31:55.678Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T09:32:08.535Z"
   },
   {
    "duration": 111,
    "start_time": "2021-11-16T09:32:10.120Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T09:32:15.732Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T09:32:29.423Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:03:03.074Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:10:01.288Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:10:46.923Z"
   },
   {
    "duration": 121,
    "start_time": "2021-11-16T10:37:46.494Z"
   },
   {
    "duration": 125,
    "start_time": "2021-11-16T10:38:20.632Z"
   },
   {
    "duration": 112,
    "start_time": "2021-11-16T10:46:53.001Z"
   },
   {
    "duration": 110,
    "start_time": "2021-11-16T10:48:25.775Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:50:18.720Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T10:50:37.649Z"
   },
   {
    "duration": 2,
    "start_time": "2021-11-16T10:50:51.884Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:51:56.237Z"
   },
   {
    "duration": 101,
    "start_time": "2021-11-16T10:53:13.791Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:55:59.186Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:56:10.751Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:56:49.038Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:56:49.174Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T10:56:49.414Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:56:49.680Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T10:56:50.370Z"
   },
   {
    "duration": 114,
    "start_time": "2021-11-16T10:59:34.518Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:01:41.201Z"
   },
   {
    "duration": 116,
    "start_time": "2021-11-16T11:01:48.754Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:02:16.685Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:02:19.479Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:02:47.067Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:02:49.353Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:03:07.835Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:03:07.953Z"
   },
   {
    "duration": 112,
    "start_time": "2021-11-16T11:07:52.072Z"
   },
   {
    "duration": 187,
    "start_time": "2021-11-16T11:09:23.468Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T11:10:01.455Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:10:05.069Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T11:10:13.376Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:10:14.434Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:10:22.853Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T11:27:29.279Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-16T11:29:08.919Z"
   },
   {
    "duration": 118,
    "start_time": "2021-11-16T11:29:46.703Z"
   },
   {
    "duration": 437,
    "start_time": "2021-11-16T11:36:02.181Z"
   },
   {
    "duration": 157,
    "start_time": "2021-11-16T11:36:14.388Z"
   },
   {
    "duration": 207,
    "start_time": "2021-11-16T11:47:15.898Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:53:52.092Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:53:52.236Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T11:59:12.005Z"
   },
   {
    "duration": 112,
    "start_time": "2021-11-16T12:00:33.446Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T12:02:14.453Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-16T12:02:39.512Z"
   },
   {
    "duration": 106,
    "start_time": "2021-11-16T12:03:03.460Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T20:37:21.139Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T20:37:22.229Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T20:38:38.806Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T20:38:41.958Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T20:43:46.551Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T20:58:21.835Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T20:59:21.872Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T20:59:45.352Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T20:59:49.646Z"
   },
   {
    "duration": 159,
    "start_time": "2021-11-17T21:02:26.949Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:03:53.461Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:03:53.694Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:05:28.145Z"
   },
   {
    "duration": 116,
    "start_time": "2021-11-17T21:05:57.787Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:06:37.993Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:06:38.261Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:11:54.358Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:12:43.846Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:13:08.773Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:14:44.441Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:15:42.059Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:15:51.995Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:15:53.923Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:15:55.282Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:16:28.492Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:16:32.603Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:17:06.941Z"
   },
   {
    "duration": 98,
    "start_time": "2021-11-17T21:18:05.733Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:21:35.255Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:21:37.804Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:23:06.071Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:23:24.799Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:23:32.591Z"
   },
   {
    "duration": 98,
    "start_time": "2021-11-17T21:28:31.559Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:28:45.448Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:29:17.303Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:29:29.617Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:29:32.681Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:36:11.474Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:36:14.791Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:36:53.943Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:36:56.165Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:37:16.590Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:37:22.702Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:38:03.479Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:38:08.601Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:38:12.928Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:38:48.896Z"
   },
   {
    "duration": 2,
    "start_time": "2021-11-17T21:38:49.171Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:39:57.889Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:39:58.057Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:41:20.108Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:41:20.629Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:42:49.136Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:43:15.137Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:43:16.766Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:43:31.711Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:43:36.312Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:45:08.825Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:45:10.119Z"
   },
   {
    "duration": 4,
    "start_time": "2021-11-17T21:45:13.748Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:45:22.219Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:45:33.412Z"
   },
   {
    "duration": 2,
    "start_time": "2021-11-17T21:46:01.885Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-17T21:46:03.628Z"
   },
   {
    "duration": 107,
    "start_time": "2021-11-17T21:47:32.512Z"
   },
   {
    "duration": 103,
    "start_time": "2021-11-17T21:50:36.243Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-18T06:28:31.440Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-18T06:29:00.168Z"
   },
   {
    "duration": 3,
    "start_time": "2021-11-18T06:31:27.008Z"
   },
   {
    "duration": 2,
    "start_time": "2021-11-18T06:35:34.288Z"
   },
   {
    "duration": 2,
    "start_time": "2021-11-18T06:38:04.527Z"
   }
  ],
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
